{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtxmVXG7-9Fp"
   },
   "source": [
    "\n",
    "# AAI612: Deep Learning & its Applications\n",
    "\n",
    "*Notebook 5.3: KerasTuner*\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/OmarMlaeb/AAI612_Malaeb/blob/master/Week%205/Notebook5.3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cGaL7GV-9Fu"
   },
   "source": [
    "Ensure that KerasTuner is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwrpgSMK-9Fv",
    "outputId": "2382cb45-aa57-419c-9aed-6e2b8ba52eca"
   },
   "outputs": [],
   "source": [
    "!pip install keras-tuner -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LO4ZBbnb-9Fx"
   },
   "source": [
    "Import KerasTuner and TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_2xfe-Nc-9Fx"
   },
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVK7rTac-9Fx",
    "tags": []
   },
   "source": [
    "`KerasTuner` lets you replace hard-coded hyperparameter values, such as units=32, with a range of possible choices, such as `Int(name=\"units\", min_value=16, max_value=64, step=16)`. This set of choices in a given model is called the search space of the hyperparameter tuning process.  To specify a search space, define a model-building function (see the next listing).  It takes an hp argument, from which you can sample hyperparameter ranges, and it returns a compiled Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GbRmbxwC-9Fy"
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(units, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehYrocAB-9Fz"
   },
   "source": [
    "**A KerasTuner `HyperModel`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiyJHI2S-9Fz"
   },
   "source": [
    "We can also adopt a more modular and configurable approach to model-building by subclassing the HyperModel class and define a build method, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZCURlILc-9F0"
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "class SimpleMLP(kt.HyperModel):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
    "        model = keras.Sequential([\n",
    "            layers.Dense(units, activation=\"relu\"),\n",
    "            layers.Dense(self.num_classes, activation=\"softmax\")\n",
    "        ])\n",
    "        optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "        return model\n",
    "\n",
    "hypermodel = SimpleMLP(num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0MF-9rp-9F1"
   },
   "source": [
    "The next step is to define a “tuner.” Schematically, you can think of a tuner as a for loop that will repeatedly\n",
    "- Pick a set of hyperparameter values\n",
    "- Call the model-building function with these values to create a model\n",
    "- Train the model and record its metrics\n",
    "\n",
    "KerasTuner has several built-in tuners available—RandomSearch, BayesianOptimization, and Hyperband. Let’s try BayesianOptimization, a tuner that attempts to make smart predictions for which new hyperparameter values are likely to perform best given the outcomes of previous choices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BUcCjNbz-9F2"
   },
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    directory=\"mnist_kt_test\",\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6hI2-oD-9F2"
   },
   "source": [
    "Display an overview of the search space via `search_space_summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEJi1z4J-9F3",
    "outputId": "09c54a38-fc4f-4a57-9f68-78e65152585f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n",
      "optimizer (Choice)\n",
      "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wXYlmVFL-9F3",
    "outputId": "1ea72858-6d59-4fc0-b4aa-d84678386000",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 35s]\n",
      "val_accuracy: 0.9741500020027161\n",
      "\n",
      "Best val_accuracy So Far: 0.9765999913215637\n",
      "Total elapsed time: 01h 32m 19s\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
    "x_train_full = x_train[:]\n",
    "y_train_full = y_train[:]\n",
    "num_val_samples = 10000\n",
    "x_train, x_val = x_train[:-num_val_samples], x_train[-num_val_samples:]\n",
    "y_train, y_val = y_train[:-num_val_samples], y_train[-num_val_samples:]\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "]\n",
    "tuner.search(\n",
    "    x_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLC-hCiJ-9F3"
   },
   "source": [
    "## Querying the best hyperparameter configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpBGd4Gf-9F4"
   },
   "source": [
    "Once the search is complete, you can query the best hyperparameter configurations, which you can use to create high-performing models that you can then retrain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1eWg5rqB-9F4"
   },
   "outputs": [],
   "source": [
    "top_n = 4\n",
    "best_hps = tuner.get_best_hyperparameters(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF2n59tJ-9F4"
   },
   "source": [
    "Before we can train on the full training data, though, there’s one last parameter we need to settle: the optimal number of epochs to train for. Typically, you’ll want to train the new models for longer than you did during the search: using an aggressive patience value in the EarlyStopping callback saves time during the search, but it may lead to under-fit models. Just use the validation set to find the best epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "M1jaGqs9-9F4"
   },
   "outputs": [],
   "source": [
    "def get_best_epoch(hp):\n",
    "    model = build_model(hp)\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", mode=\"min\", patience=10)\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=128,\n",
    "        callbacks=callbacks)\n",
    "    val_loss_per_epoch = history.history[\"val_loss\"]\n",
    "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    return best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CItGEiyL-9F5"
   },
   "source": [
    "Finally, train on the full dataset for just a bit longer than this epoch count, since\n",
    "you’re training on more data; 20% more in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btvgt5hl-9F5",
    "outputId": "a4670b53-ce3a-4f9c-cd6c-143be8d995af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.4199 - accuracy: 0.8892 - val_loss: 0.2393 - val_accuracy: 0.9337\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2122 - accuracy: 0.9399 - val_loss: 0.1774 - val_accuracy: 0.9496\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1655 - accuracy: 0.9518 - val_loss: 0.1554 - val_accuracy: 0.9554\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1371 - accuracy: 0.9605 - val_loss: 0.1380 - val_accuracy: 0.9613\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1168 - accuracy: 0.9661 - val_loss: 0.1215 - val_accuracy: 0.9646\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1016 - accuracy: 0.9705 - val_loss: 0.1187 - val_accuracy: 0.9656\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.9746 - val_loss: 0.1108 - val_accuracy: 0.9691\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0800 - accuracy: 0.9763 - val_loss: 0.1059 - val_accuracy: 0.9703\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.9792 - val_loss: 0.1047 - val_accuracy: 0.9700\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0650 - accuracy: 0.9812 - val_loss: 0.1031 - val_accuracy: 0.9714\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9827 - val_loss: 0.1023 - val_accuracy: 0.9711\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0542 - accuracy: 0.9846 - val_loss: 0.0995 - val_accuracy: 0.9726\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0495 - accuracy: 0.9861 - val_loss: 0.1042 - val_accuracy: 0.9718\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0458 - accuracy: 0.9863 - val_loss: 0.1014 - val_accuracy: 0.9727\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0418 - accuracy: 0.9879 - val_loss: 0.0999 - val_accuracy: 0.9733\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0390 - accuracy: 0.9891 - val_loss: 0.0984 - val_accuracy: 0.9730\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0357 - accuracy: 0.9901 - val_loss: 0.1010 - val_accuracy: 0.9721\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0334 - accuracy: 0.9908 - val_loss: 0.0997 - val_accuracy: 0.9741\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0309 - accuracy: 0.9918 - val_loss: 0.1014 - val_accuracy: 0.9729\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0283 - accuracy: 0.9925 - val_loss: 0.1020 - val_accuracy: 0.9745\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 0.1093 - val_accuracy: 0.9729\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0242 - accuracy: 0.9937 - val_loss: 0.1071 - val_accuracy: 0.9729\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9943 - val_loss: 0.1052 - val_accuracy: 0.9734\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9949 - val_loss: 0.1090 - val_accuracy: 0.9736\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.1129 - val_accuracy: 0.9730\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 0.1116 - val_accuracy: 0.9737\n",
      "Best epoch: 16\n",
      "Epoch 1/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3922 - accuracy: 0.8960\n",
      "Epoch 2/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1908 - accuracy: 0.9450\n",
      "Epoch 3/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1462 - accuracy: 0.9575\n",
      "Epoch 4/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1206 - accuracy: 0.9646\n",
      "Epoch 5/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1024 - accuracy: 0.9704\n",
      "Epoch 6/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9740\n",
      "Epoch 7/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0799 - accuracy: 0.9772\n",
      "Epoch 8/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0721 - accuracy: 0.9785\n",
      "Epoch 9/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.9811\n",
      "Epoch 10/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.9827\n",
      "Epoch 11/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0543 - accuracy: 0.9840\n",
      "Epoch 12/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0501 - accuracy: 0.9861\n",
      "Epoch 13/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0464 - accuracy: 0.9866\n",
      "Epoch 14/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0428 - accuracy: 0.9880\n",
      "Epoch 15/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0401 - accuracy: 0.9887\n",
      "Epoch 16/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0373 - accuracy: 0.9895\n",
      "Epoch 17/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0346 - accuracy: 0.9904\n",
      "Epoch 18/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0324 - accuracy: 0.9909\n",
      "Epoch 19/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0301 - accuracy: 0.9915\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9756\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.4305 - accuracy: 0.8846 - val_loss: 0.2361 - val_accuracy: 0.9339\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2240 - accuracy: 0.9362 - val_loss: 0.1886 - val_accuracy: 0.9465\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.9492 - val_loss: 0.1539 - val_accuracy: 0.9568\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1459 - accuracy: 0.9577 - val_loss: 0.1405 - val_accuracy: 0.9597\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1250 - accuracy: 0.9636 - val_loss: 0.1282 - val_accuracy: 0.9641\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1100 - accuracy: 0.9680 - val_loss: 0.1170 - val_accuracy: 0.9662\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9717 - val_loss: 0.1132 - val_accuracy: 0.9678\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.9743 - val_loss: 0.1075 - val_accuracy: 0.9688\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0784 - accuracy: 0.9775 - val_loss: 0.1124 - val_accuracy: 0.9678\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0719 - accuracy: 0.9789 - val_loss: 0.1028 - val_accuracy: 0.9705\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0655 - accuracy: 0.9813 - val_loss: 0.1011 - val_accuracy: 0.9713\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.9824 - val_loss: 0.1026 - val_accuracy: 0.9710\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0553 - accuracy: 0.9847 - val_loss: 0.1006 - val_accuracy: 0.9714\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0513 - accuracy: 0.9853 - val_loss: 0.0996 - val_accuracy: 0.9717\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0471 - accuracy: 0.9867 - val_loss: 0.0966 - val_accuracy: 0.9729\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0440 - accuracy: 0.9878 - val_loss: 0.1034 - val_accuracy: 0.9704\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0402 - accuracy: 0.9890 - val_loss: 0.0949 - val_accuracy: 0.9719\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0376 - accuracy: 0.9896 - val_loss: 0.1030 - val_accuracy: 0.9702\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0350 - accuracy: 0.9902 - val_loss: 0.0974 - val_accuracy: 0.9730\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0327 - accuracy: 0.9908 - val_loss: 0.1042 - val_accuracy: 0.9723\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0303 - accuracy: 0.9919 - val_loss: 0.1046 - val_accuracy: 0.9732\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0279 - accuracy: 0.9928 - val_loss: 0.1000 - val_accuracy: 0.9733\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0260 - accuracy: 0.9932 - val_loss: 0.0994 - val_accuracy: 0.9734\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 0.1019 - val_accuracy: 0.9733\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9943 - val_loss: 0.1039 - val_accuracy: 0.9731\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9947 - val_loss: 0.1027 - val_accuracy: 0.9741\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.1115 - val_accuracy: 0.9714\n",
      "Best epoch: 17\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3788 - accuracy: 0.8968\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1922 - accuracy: 0.9443\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1448 - accuracy: 0.9581\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1172 - accuracy: 0.9666\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9711\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0866 - accuracy: 0.9746\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0766 - accuracy: 0.9777\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0686 - accuracy: 0.9794\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0624 - accuracy: 0.9819\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0571 - accuracy: 0.9829\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0519 - accuracy: 0.9844\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0483 - accuracy: 0.9864\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0442 - accuracy: 0.9875\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0408 - accuracy: 0.9886\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0382 - accuracy: 0.9890\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0356 - accuracy: 0.9901\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0333 - accuracy: 0.9908\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0308 - accuracy: 0.9916\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0288 - accuracy: 0.9924\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0265 - accuracy: 0.9931\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9744\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.4214 - accuracy: 0.8850 - val_loss: 0.2382 - val_accuracy: 0.9340\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2243 - accuracy: 0.9366 - val_loss: 0.1787 - val_accuracy: 0.9511\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1690 - accuracy: 0.9512 - val_loss: 0.1528 - val_accuracy: 0.9567\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1361 - accuracy: 0.9603 - val_loss: 0.1307 - val_accuracy: 0.9629\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1137 - accuracy: 0.9674 - val_loss: 0.1203 - val_accuracy: 0.9660\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9716 - val_loss: 0.1064 - val_accuracy: 0.9692\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0868 - accuracy: 0.9754 - val_loss: 0.1015 - val_accuracy: 0.9702\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9774 - val_loss: 0.0982 - val_accuracy: 0.9711\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0692 - accuracy: 0.9800 - val_loss: 0.0959 - val_accuracy: 0.9718\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9820 - val_loss: 0.0954 - val_accuracy: 0.9724\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0570 - accuracy: 0.9836 - val_loss: 0.0980 - val_accuracy: 0.9702\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0516 - accuracy: 0.9852 - val_loss: 0.0935 - val_accuracy: 0.9723\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0471 - accuracy: 0.9867 - val_loss: 0.0925 - val_accuracy: 0.9730\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0433 - accuracy: 0.9879 - val_loss: 0.0922 - val_accuracy: 0.9736\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0401 - accuracy: 0.9888 - val_loss: 0.0975 - val_accuracy: 0.9725\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0367 - accuracy: 0.9897 - val_loss: 0.0910 - val_accuracy: 0.9737\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0336 - accuracy: 0.9906 - val_loss: 0.0920 - val_accuracy: 0.9750\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0310 - accuracy: 0.9914 - val_loss: 0.0930 - val_accuracy: 0.9754\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0287 - accuracy: 0.9922 - val_loss: 0.0998 - val_accuracy: 0.9736\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0265 - accuracy: 0.9931 - val_loss: 0.0933 - val_accuracy: 0.9760\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9935 - val_loss: 0.0944 - val_accuracy: 0.9762\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9946 - val_loss: 0.0957 - val_accuracy: 0.9757\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0201 - accuracy: 0.9948 - val_loss: 0.0950 - val_accuracy: 0.9763\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0190 - accuracy: 0.9955 - val_loss: 0.0941 - val_accuracy: 0.9770\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.0989 - val_accuracy: 0.9758\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0163 - accuracy: 0.9959 - val_loss: 0.1008 - val_accuracy: 0.9749\n",
      "Best epoch: 16\n",
      "Epoch 1/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3847 - accuracy: 0.8968\n",
      "Epoch 2/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1975 - accuracy: 0.9441\n",
      "Epoch 3/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1528 - accuracy: 0.9558\n",
      "Epoch 4/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1249 - accuracy: 0.9643\n",
      "Epoch 5/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1048 - accuracy: 0.9696\n",
      "Epoch 6/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9737\n",
      "Epoch 7/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0798 - accuracy: 0.9770\n",
      "Epoch 8/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0715 - accuracy: 0.9793\n",
      "Epoch 9/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9814\n",
      "Epoch 10/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9832\n",
      "Epoch 11/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0533 - accuracy: 0.9847\n",
      "Epoch 12/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0490 - accuracy: 0.9859\n",
      "Epoch 13/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0451 - accuracy: 0.9872\n",
      "Epoch 14/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0416 - accuracy: 0.9880\n",
      "Epoch 15/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0384 - accuracy: 0.9894\n",
      "Epoch 16/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0358 - accuracy: 0.9900\n",
      "Epoch 17/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0332 - accuracy: 0.9910\n",
      "Epoch 18/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0299 - accuracy: 0.9919\n",
      "Epoch 19/19\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0284 - accuracy: 0.9921\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9743\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.4186 - accuracy: 0.8847 - val_loss: 0.2476 - val_accuracy: 0.9291\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2257 - accuracy: 0.9355 - val_loss: 0.1892 - val_accuracy: 0.9460\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.9493 - val_loss: 0.1589 - val_accuracy: 0.9550\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1461 - accuracy: 0.9577 - val_loss: 0.1425 - val_accuracy: 0.9586\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1241 - accuracy: 0.9639 - val_loss: 0.1284 - val_accuracy: 0.9621\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1077 - accuracy: 0.9680 - val_loss: 0.1197 - val_accuracy: 0.9647\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9723 - val_loss: 0.1083 - val_accuracy: 0.9688\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0840 - accuracy: 0.9759 - val_loss: 0.1078 - val_accuracy: 0.9677\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0757 - accuracy: 0.9783 - val_loss: 0.1034 - val_accuracy: 0.9693\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0678 - accuracy: 0.9801 - val_loss: 0.0978 - val_accuracy: 0.9701\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9825 - val_loss: 0.0941 - val_accuracy: 0.9704\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0560 - accuracy: 0.9838 - val_loss: 0.0962 - val_accuracy: 0.9705\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0519 - accuracy: 0.9850 - val_loss: 0.1010 - val_accuracy: 0.9697\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0471 - accuracy: 0.9866 - val_loss: 0.0974 - val_accuracy: 0.9708\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0435 - accuracy: 0.9878 - val_loss: 0.0964 - val_accuracy: 0.9718\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0400 - accuracy: 0.9890 - val_loss: 0.0951 - val_accuracy: 0.9715\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0365 - accuracy: 0.9899 - val_loss: 0.0992 - val_accuracy: 0.9714\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0340 - accuracy: 0.9907 - val_loss: 0.0990 - val_accuracy: 0.9711\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0314 - accuracy: 0.9915 - val_loss: 0.0955 - val_accuracy: 0.9732\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0292 - accuracy: 0.9919 - val_loss: 0.1000 - val_accuracy: 0.9714\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0269 - accuracy: 0.9928 - val_loss: 0.1007 - val_accuracy: 0.9728\n",
      "Best epoch: 11\n",
      "Epoch 1/13\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3932 - accuracy: 0.8934\n",
      "Epoch 2/13\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2060 - accuracy: 0.9415\n",
      "Epoch 3/13\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1535 - accuracy: 0.9562\n",
      "Epoch 4/13\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1224 - accuracy: 0.9646\n",
      "Epoch 5/13\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1021 - accuracy: 0.9702\n",
      "Epoch 6/13\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0880 - accuracy: 0.9738\n",
      "Epoch 7/13\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0766 - accuracy: 0.9772\n",
      "Epoch 8/13\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0688 - accuracy: 0.9800\n",
      "Epoch 9/13\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0617 - accuracy: 0.9823\n",
      "Epoch 10/13\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0561 - accuracy: 0.9833\n",
      "Epoch 11/13\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0507 - accuracy: 0.9847\n",
      "Epoch 12/13\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0470 - accuracy: 0.9863\n",
      "Epoch 13/13\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0428 - accuracy: 0.9877\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0807 - accuracy: 0.9766\n"
     ]
    }
   ],
   "source": [
    "def get_best_trained_model(hp):\n",
    "    best_epoch = get_best_epoch(hp)\n",
    "    model = build_model(hp)\n",
    "    model.fit(\n",
    "        x_train_full, y_train_full,\n",
    "        batch_size=128, epochs=int(best_epoch * 1.2))\n",
    "    return model\n",
    "\n",
    "best_models = []\n",
    "for hp in best_hps:\n",
    "    model = get_best_trained_model(hp)\n",
    "    model.evaluate(x_test, y_test)\n",
    "    best_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "admpY_Tt-9F6",
    "outputId": "8acabee2-dbeb-49aa-cc38-7001e6be9526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n"
     ]
    }
   ],
   "source": [
    "best_models = tuner.get_best_models(top_n)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
